{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('saves/model')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tok_tfm = pickle.load(open('saves/tok_tfm.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(sm_base, gen_len, vocab_sz, inp):\n",
    "    with torch.no_grad():\n",
    "        for _ in range(gen_len):\n",
    "            batched = inp[None,:] # add batch dimension\n",
    "            preds = model(batched)\n",
    "            logits = preds[0,-1,:] # get only the last predicted token\n",
    "            logits = logits.numpy() # convert to numpy for weighted random choice functionality\n",
    "            logits = logits[1:] # don't predict xxunk (position 0)\n",
    "            exped = sm_base**logits # like softmax, but with an adjustable base instead of e\n",
    "            probs = exped / exped.sum() \n",
    "            new = np.random.choice(np.arange(1, vocab_sz), size=1, p=probs) # don't predict xxunk\n",
    "            new_t = torch.tensor(new)\n",
    "            inp = torch.cat([inp, new_t])\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text(sm_base,gen_len,inp):\n",
    "    inp = inp.split(' ')\n",
    "    inp = tok_tfm.encode(inp)\n",
    "    output = generate(sm_base, gen_len, tok_tfm.count, inp)\n",
    "    joined = ' '.join(tok_tfm.decode(output))\n",
    "    fixed = re.sub(r' ([.,?:;’”])', '\\\\1', joined)\n",
    "    fixed = re.sub(r'([“‘]) ', '\\\\1', fixed)\n",
    "    fixed = re.sub(r'’ s', '’s', fixed)\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_text(4,100,\"the only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
