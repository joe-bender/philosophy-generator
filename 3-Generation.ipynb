{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I generate text using the saved model from the notebook `2-Training`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I import the libraries I need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import numpy as np\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I load the saved model from the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LangModel(\n",
       "  (emb): Embedding(3001, 200)\n",
       "  (lstm1): LSTM(200, 300, batch_first=True)\n",
       "  (lstm2): LSTM(300, 200, batch_first=True)\n",
       "  (lin): Linear(in_features=200, out_features=3001, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('saves/model')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also need the `TokTransform` object which translates between text tokens and tensors of numbers, and which stores the vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tok_tfm = pickle.load(open('saves/tok_tfm.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function used for text generation takes an input tensor and adds more numbers onto the end of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(sm_base, gen_len, vocab_sz, inp):\n",
    "    with torch.no_grad():\n",
    "        for _ in range(gen_len):\n",
    "            batched = inp[None,:] # add batch dimension\n",
    "            preds = model(batched)\n",
    "            logits = preds[0,-1,:] # get only the last predicted token\n",
    "            logits = logits.numpy() # convert to numpy for weighted random choice functionality\n",
    "            logits = logits[1:] # don't predict xxunk (position 0)\n",
    "            exped = sm_base**logits # like softmax, but with an adjustable base instead of e\n",
    "            probs = exped / exped.sum() \n",
    "            new = np.random.choice(np.arange(1, vocab_sz), size=1, p=probs) # don't predict xxunk\n",
    "            new_t = torch.tensor(new)\n",
    "            inp = torch.cat([inp, new_t])\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sm_base` controls the base of the softmax function used to generate the probability distribution that tokens are randomly selected from. The standard softmax function uses e as the base, but lowering the base smooths out the probabilities, while increasing the base exaggerates the differences between probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text(sm_base,gen_len,inp):\n",
    "    inp = inp.split(' ')\n",
    "    inp = tok_tfm.encode(inp)\n",
    "    output = generate(sm_base, gen_len, tok_tfm.count, inp)\n",
    "    joined = ' '.join(tok_tfm.decode(output))\n",
    "    fixed = re.sub(r' ([.,?:;’”])', '\\\\1', joined)\n",
    "    fixed = re.sub(r'([“‘]) ', '\\\\1', fixed)\n",
    "    fixed = re.sub(r'’ s', '’s', fixed)\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I set random seeds for all sources of randomness in this notebook, so that the results will be the same each time it is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A low softmax base will result in more randomness in the generated text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the necessity of, and in the world of sense the whole? is properly, on the internal unity of simple s in relation to each other, and criticism, as primal being does not presuppose use, à posteriori as a explanation of time must be subject,'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_text(sm_base=3,gen_len=50,inp=\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of random words, but not much repetition. Even with the high randomness, there is a sense of intelligence to th generated text, instead of complete randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With slightly less randomness, we get a more coherent-sounding text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the conception of the understanding, in which the form of the understanding is not the cause of the soul in space, is only in the subjective conditions of time. for if we do not possess any relation to the most whole. it is evident that, as'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_text(sm_base=5,gen_len=50,inp=\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first sentence seems like it could have been written by a philosopher. There is a little more repetition now, for example the word \"understanding\". The second sentence ends abruptly, but that could just be the fault of the randomly selected period token. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With even less randomness, we get a lot more repetition of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the conception of a thing which is the synthesis of perception, and consequently the conception of a supreme being, in the same time, which is not the empirical condition of the conception. the former is an empirical conception, in which the conception of a thing in'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_text(sm_base=10,gen_len=50,inp=\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The consistent return to the word \"conception\" seems to stop the generated text from getting anywhere new. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, with very little randomness, we get something more coherent, but that might be due to memorization of pieces of the original text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the conception of a thing in general, which is not a thing in itself, and which is not a necessary being. but this is not a transcendental idea, which is not a thing in itself, but only in the sphere of experience, and not as'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_text(sm_base=100,gen_len=50,inp=\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But even if there is some memorization of phrases, we still get a much different result using the same settings again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the same time. but this is not an object of the subject, and is not the objective validity of the possibility of a thing which is not an object, but only in the sphere of experience, and the same with the conception of a thing in general'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_text(sm_base=100,gen_len=50,inp=\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't expect to get amazing results by training from scratch on a single book for only a few epochs, but I'm still amazed by how pseudo-intelligent the generated text can seem at times. I limited the model's vocabulary to 3000 in order to get a little less randomness in word selection during text generation, and it seems to have kept it from picking even more random-seeming words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder how much information about the workings of language could be learned from this one book, if I used a larger model with some regularization and trained it for much longer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could also try other forms of token selection for the generation process, such as only selecting from the top n most likely next tokens. I think my method of smoothing or exaggerating the softmax likelihoods resulting in a good amount of randomness while also keeping some coherence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
